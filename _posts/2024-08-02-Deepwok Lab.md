---
title: Deepwok Lab 机器学习科研
header:
  teaser: "assets/wide_bgs/coffee.jpeg"
categories:
  - Projects
tags:
    - pytorch
    - machine learning
    - internship
---

### 项目概述
深度神经网络（DNN）在部署于定制的硬件加速器上时，能够实现高性能和高能效。数据流架构由于其层级流水结构和可扩展性，特别有效。

当前用于利用权重和激活稀疏性的方法往往忽视了数据流架构，从而错失了优化机会。我们提出了硬件感知稀疏性搜索（HASS），这是一种通过软硬件协同优化在数据流加速器中利用稀疏性的新方法。HASS系统地寻找有效的稀疏性解决方案，相比现有设计取得了显著的改进。

### 贡献

我的大部分工作是[MASE](https://github.com/jianyicheng/mase-tools)上的软件开发，更具体地说，是MASE的软件栈Machop的开发。

**[Mase（机器学习加速器系统探索工具）](https://github.com/jianyicheng/mase-tools)** 提供了一种高效且可扩展的方法，通过直接映射到高效的流式加速器系统，探索用于计算大型ML模型的加速器系统。

1. Mase提供了命令行接口，可以使用指定的数据集从零开始训练模型。为了评估新的数据流加速器的效率，我在Mase中集成了RepVGG模型的支持，整理并记录了详细的操作流程供未来开发者使用。

2. 对DNN硬件加速器的探索需要硬件-软件协同仿真。我协助编写了将元数据发送给硬件团队的脚本，这有助于验证硬件实现的完整性并识别差异。脚本包括：

- **转换脚本：** 对指定模型运行转换过程，例如量化或剪枝。
- **搜索脚本：** 在搜索空间上应用给定的搜索策略，以优化指定的一组硬件/软件指标。

### 论文发表

研究论文已在FPT上发表。您可以在[这里](https://arxiv.org/abs/2406.03088)查看该论文。